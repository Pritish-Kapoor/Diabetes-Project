# -*- coding: utf-8 -*-
"""Diabetes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_amcWeIF1a1BND4aAxuh_mrBtkT3mfFt
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, Normalizer, OrdinalEncoder
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from xgboost import XGBClassifier
import joblib
import warnings
warnings.filterwarnings('ignore')

df=pd.read_csv('diabetes.csv')
df.head()

df.isnull().sum()

df['Outcome'].value_counts()

# # Define function to categorize glucose levels
# def categorize_glucose(glucose):
#     if glucose <= 70:
#         return 'low'
#     elif 71 <= glucose <= 99:
#         return 'normal'
#     elif 100 <= glucose <= 140:
#         return 'high'
#     else:
#         return 'very high'

# # Apply the function to create new column
# df["Sugar range"] = df["Glucose"].apply(categorize_glucose)

# df.head()

# # Define function to categorize age levels
# def categorize_age(age):
#     if 20<= age <= 40:
#         return 'early adulthood'
#     elif 41 <= age <= 65:
#         return 'middle adulthood'
#     else:
#         return 'late adulthood'

# # Apply the function to create new column
# df["Age range"] = df["Age"].apply(categorize_age)

# df.head()

# df['Sugar range'] = df['Sugar range'].astype(str)
# oe=OrdinalEncoder(categories=[['low', 'normal', 'high', 'very high']])
# df['Sugar range encoded'] = oe.fit_transform(df[['Sugar range']])

# df['Age range'] = df['Age range'].astype(str)
# oe1=OrdinalEncoder(categories=[['early adulthood', 'middle adulthood', 'late adulthood']])
# df['Age range encoded'] = oe1.fit_transform(df[['Age range']])

df.head()

X=df.drop('Outcome',axis=1)
y=df['Outcome']

smote=SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)
X_bal, y_bal=smote.fit_resample(X,y)

print(X_bal.shape)
print(y_bal.shape)

scaler=StandardScaler()
X_bal=scaler.fit_transform(X_bal)
X_scaler=pd.DataFrame(X_bal,columns=X.columns)
X_scaler.head()

X_train, X_test, y_train, y_test=train_test_split(X_bal,y_bal,test_size=0.2,random_state=42)

classifiers = [
            RandomForestClassifier(n_estimators=10,random_state=42),
            AdaBoostClassifier(),
            GradientBoostingClassifier(),
            LogisticRegression(),
            SVC(),
            KNeighborsClassifier(),
            DecisionTreeClassifier(),
            GaussianNB(),
            XGBClassifier()
]
vCounter=0
for cls in classifiers:
  vCounter+=1
  print(f"Classifier {vCounter}: {cls.__class__.__name__}")
  cls.fit(X_train, y_train)
  y_pred = cls.predict(X_test)
  accuracy = accuracy_score(y_test, y_pred)
  print(f"Accuracy:{str(round(accuracy*100,2))}")
  print("==========================================\n")

model=XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
model.fit(X_train,y_train)

y_pred=model.predict(X_test)

accuracy_score=accuracy_score(y_test,y_pred)
f1_score=f1_score(y_test,y_pred)
classification_report=classification_report(y_test,y_pred)
confusion_matrix=confusion_matrix(y_test,y_pred)

print(f'accuracy:{accuracy_score}')
print(f'f1 score:{f1_score}')
print(f'classification report:{classification_report}')
print(f'confusion matrix:{confusion_matrix}')

# #Model Save
# joblib.dump(model, "model.pkl")
model.save_model("model.json")